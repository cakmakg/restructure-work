ğŸ¤– RAG-Basierter KI-Chat-Assistent (MERN Stack) Dieses Projekt ist eine RAG-Anwendung 
![Proje Ã–nizleme](./client/assets/projeckt.png)


(Retrieval-Augmented Generation), die es Benutzern ermÃ¶glicht, eigene PDF-Dokumente hochzuladen und einen KI-gestÃ¼tzten Chat Ã¼ber diese Inhalte zu fÃ¼hren.

Benutzer kÃ¶nnen Dokumente in bestimmte Kategorien einteilen und beim Stellen von Fragen Antworten erhalten, die nur auf den Daten der ausgewÃ¤hlten Kategorie basieren.

ğŸš€ Ãœber das Projekt Diese Anwendung geht Ã¼ber Standard-Chatbots hinaus und ermÃ¶glicht es Ihnen, mit Ihren eigenen Daten zu sprechen. Die RAG-Architektur wird verwendet, um Halluzinationen von LLMs (Large Language Models) zu verhindern und prÃ¤zise Informationen bereitzustellen.

Hauptmerkmale:

ğŸ“„ PDF-Upload & Verarbeitung: Wandelt PDF-Dateien in Text um und unterteilt sie in Abschnitte (Chunking).

ğŸ—‚ï¸ Kategoriebasierte Filterung: Daten werden beim Hochladen getaggt (z. B. "Test-1", "Vorlesungsnotizen"). Suchanfragen werden nur innerhalb der ausgewÃ¤hlten Kategorie durchgefÃ¼hrt.

ğŸ§  Vektorsuche (Vector Search): Semantische Suche wird mithilfe von MongoDB Atlas Vector Search durchgefÃ¼hrt.

âš¡ Streaming-Antwort: Die KI-Antwort erscheint Teil fÃ¼r Teil auf dem Bildschirm (Echtzeit-Erlebnis wie bei einer Schreibmaschine).

ğŸ”’ Lokale Embeddings: Die Vektorisierung (Embedding) erfolgt serverseitig (Xenova/transformers), um externe AbhÃ¤ngigkeiten zu reduzieren.

ğŸ› ï¸ Technologien (Tech Stack) Dieses Projekt wurde mit modernen Webtechnologien entwickelt:

Frontend React (Vite): Schnelle und modulare BenutzeroberflÃ¤che.

Fetch API (Stream Reader): Zum Lesen der stÃ¼ckweise Ã¼bertragenen Daten vom Backend.

CSS Modules / Inline Styles: Sauberes und angepasstes Design.

Backend Node.js & Express: API- und Serververwaltung.

Multer: Verarbeitung von Datei-Uploads.

PDF-Parse: Konvertierung von PDF-Inhalten in Text.

LangChain / Transformers.js: Umwandlung von Texten in Vektorformate (Embeddings).

Groq SDK (Llama-3): Hochgeschwindigkeits-LLM (KI-Engine).

Datenbank MongoDB Atlas: Datenspeicherung.

Atlas Vector Search: Vektorbasierte Dokumentensuche und Filterung.

âš™ï¸ Installation Befolgen Sie diese Schritte, um das Projekt auf Ihrem lokalen Computer auszufÃ¼hren:

Repository klonen Bash git clone https://github.com/IHR_BENUTZERNAME/REPO_NAME.git cd REPO_NAME
Backend-Einrichtung Wechseln Sie in das Server-Verzeichnis und installieren Sie die AbhÃ¤ngigkeiten:
Bash cd server npm install Erstellen Sie eine .env-Datei im server-Ordner und fÃ¼gen Sie folgende Informationen hinzu:

Kod snippet'i PORT=5000 MONGODB_URI=mongodb+srv://:@cluster.mongodb.net/rag_db?retryWrites=true&w=majority GROQ_API_KEY=gsk_... (Ihr Groq API-SchlÃ¼ssel) Starten Sie den Server:

Bash node server.js

ğŸ§  Wie es funktioniert (Architektur) Aufnahme (Ingestion): Der Benutzer lÃ¤dt ein PDF hoch und legt eine Kategorie fest (z. B. HR-Richtlinien).

Einbettung (Embedding): Das Backend unterteilt den PDF-Text in kleine StÃ¼cke und wandelt jedes StÃ¼ck in numerische Vektoren um.

Speicherung: Vektoren und Textteile werden zusammen mit dem Kategorie-Tag in MongoDB gespeichert.

Abruf (Retrieval): Wenn der Benutzer eine Frage stellt, wird diese Frage ebenfalls in einen Vektor umgewandelt.

Suche: MongoDB Atlas findet die semantisch Ã¤hnlichsten Dokumententeile zum Fragevektor (nur innerhalb der ausgewÃ¤hlten Kategorie!).

Generierung: Die gefundenen Teile + die Benutzerfrage werden an die Groq API (Llama-3) gesendet. Die KI generiert daraufhin die Antwort basierend auf diesen Informationen.

ğŸ”® Roadmap (Geplante Funktionen) [ ] Verbesserte BenutzeroberflÃ¤che (UI/UX).

[ ] Speichern des Chatverlaufs (Chat History).

[ ] UnterstÃ¼tzung fÃ¼r weitere Dateiformate (Word, Txt).

[ ] Mehrsprachigkeit.
